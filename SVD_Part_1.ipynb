{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSJ9SR5Td2zg"
      },
      "source": [
        "- title: SVD Series Part 1: Introduction\n",
        "- date: 2020-09-10 \n",
        "- category: Numerical Analysis\n",
        "- tags: linear algebra\n",
        "- slug: svd-introduction\n",
        "- authors: Anas Bouzid\n",
        "- summary: It is a very simple and useful matrix decomposition. Maybe the second most important algorithm of the last 100 years - coming after Fast Fourier Transform - and this algorithm is revolutionizing what we do with large data sets. With this decomposition, we will be able to build facial recognition software which can be used to classify illness or genetic features. Singular Value Decomposition allows you to take training data from your past experience and essentially build a model and extrapolate what other situations would look like. This is the bases for Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zZHi7bKXUsA"
      },
      "source": [
        "## Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TomfH5KWXn-6"
      },
      "source": [
        "Singular Value Decomposition is maybe the second most important algorithm of the last 100 years - coming after Fast Fourier Transform - and this algorithm is revolutionizing what we do with large data sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQoaTD86Xt-g"
      },
      "source": [
        "Well, what is it?\n",
        "\n",
        "> **It is a very simple and useful matrix decomposition**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVtEwdb3X4Yi"
      },
      "source": [
        "With this decomposition, we will be able to build facial recognition software which can be used to classify illness or genetic features. \n",
        "\n",
        "\n",
        "Singular Value Decomposition allows you to take training data from your past experience and essentially build a model and extrapolate what other situations would look like. **This is the bases for Machine Learning.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DObi90qUYHJE"
      },
      "source": [
        "A couple basic takeaways to keep in mind:\n",
        "\n",
        ">  **SVD is especially useful for when you have \"big data\".**\n",
        "\n",
        "\n",
        "> **SVD is a way of extracting the most important (dominant) features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ziQnO0RXumK"
      },
      "source": [
        "What it means for these features to be dominant is that they come up again and again; these are features in your data that you see over and over again; they are strongly correlated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPHoLyesYXyz"
      },
      "source": [
        "## What does this thing actually look like?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOQ1oWdYYAL"
      },
      "source": [
        "Lets say we have a data matrix $X$,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wep5Wt4YYlya"
      },
      "source": [
        "\\begin{align*}\n",
        "    X = \\left[ \n",
        "    \\begin{matrix}\n",
        "    | & | & | & & | \\\\\n",
        "    x_1 & x_2 & x_3 & \\cdots & x_m \\\\\n",
        "    | & | & | & & |  \n",
        "    \\end{matrix}\n",
        "    \\right],\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f8iuKiawn3_"
      },
      "source": [
        "where each $x_i$ is a $n\\times 1$ column vector. We see that here, $X$ is an $n\\times m$ matrix. Each vector $x_i$ represents some big measurement like, for example, all temperature measurements from all weather stations (on the ith day). Thus, each column is a high-dimensional measurement where the dimensions are all the different weather stations (whose measurements are independent from the measurements of other weather stations). In $X$, we have $m$ examples of each measurement. These $m$ examples may be a sequence of measurements in time (like different days) which are refered to as snapshots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQL_cH6vwoFR"
      },
      "source": [
        "Another example of the kind of data that $x_i$ may contain is the number people infected with a virus in all $n$ counties in the landlocked part of the US. And each $x_i$ contains this data for a single month and so $X$ contains this data for $m$ months."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1kvuIGbMV7v"
      },
      "source": [
        "Now, as far the dimensions of the data matrix goes, it is likely that $m >> n$ in the examples above. This isnt always the case, some data sets may have $n>>m$. An example could result from any high frequency measurement apparatus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oSNV-XdwoTU"
      },
      "source": [
        "So, what we want to do with this data is find possible correlations in the data. We want to uncover possible correlations between counties or even regions of the US and virus infections or perhaps correlations between virus infections in these regions and months. The results may uncover where the virus originated and how it could have spread.\n",
        "\n",
        "> **We want to find the dominant features in the data set.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyM-9UZRHefp"
      },
      "source": [
        "Singular Value Decomposition is a way of decomposing the matrix $X$ into matrices that have special properties that allow for more things that can be done to $X$ that may reveal information/features. Moreover, these special matricies, as a concequence of their properties and relationship to the data, have the potential to being meaningful as well. \n",
        "\n",
        "In this decomposition, $X$ is represented as the product of three other matrices as follows,\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ir3_OKEJEh3"
      },
      "source": [
        "\\begin{align*}\n",
        "X = U \\Sigma V^*,\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16HKPI7wJkZZ"
      },
      "source": [
        "where $V*$ is the complex conjugate transpose of $V$. For the most part, we will only be dealing with **real value data** in which case the data becomes,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyQrhBIyJ8l9"
      },
      "source": [
        "\\begin{align*}\n",
        "X = U \\Sigma V^T,\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu7Sm8X5KLVt"
      },
      "source": [
        "### Properties of $U, \\Sigma,$ and $ V$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9SCQjudKY0O"
      },
      "source": [
        "By the order in the product, we can infer that \n",
        "\n",
        "\n",
        "* $U$ is an $n\\times n$ square matrix\n",
        "* $\\Sigma$ is an $n\\times m$ matrix\n",
        "* $V$ is an $m\\times m$ square matrix\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9snkDGNLMr"
      },
      "source": [
        "The first and last matrices on the right side of the decomposition expression, $U$ and $V$ are extremely special matrices. They belong to class of matrices called unitary matrices.\n",
        "\n",
        "\n",
        "\n",
        "> **$U$ and $V$ are unitary matrices**\n",
        "\n",
        "A matrix $U$ is unitary if it satisfies the following equation,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "418K1-lSNLzt"
      },
      "source": [
        "\\begin{align*}\n",
        "UU^* = U^* U = \\mathbb{I}_{n\\times n}.\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o4p2swmNMEt"
      },
      "source": [
        "From this, an obvious property of any unitary matrix is that its inverse is also its complex conjugate transpose and for a real-valued matrix, its inverse is just its transpose.\n",
        "\n",
        "\n",
        "> **The inverse of real-valued $U$ and $V$ are $U^T$ and $V^T$ respectively.**\n",
        "\n",
        "**The immediate benefit of this property is that the inverses are easy to compute (less resource intensive for computers to compute).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KnUd9zVSIPb"
      },
      "source": [
        "Unitary matrices also have geometric properties such as the fact that two vectors mapped to two new vectors using a unitary matrix will have the distance and angle between the two preserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0XuJ6FvNMSL"
      },
      "source": [
        "Specifically, with *Single* Value Decomposition, $U$ and $V$ are not only unitary matrices but unitary matrices that result in $\\Sigma$ being a diagonal matrix in order to satisfy the SVD equation. The values on the diagonal are called singular values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h18XvWEOYTgy"
      },
      "source": [
        "\\begin{align*}\n",
        "n > m : &&\n",
        "\\Sigma = \\left[\\begin{matrix}\n",
        "\\sigma_1 & 0& 0&\\cdots &0\\\\\n",
        "0& \\sigma_2 &0&\\cdots &0\\\\\n",
        "0&0& \\sigma_3 &\\cdots &0\\\\\n",
        "0&0&0&\\ddots&0\\\\\n",
        "0&0&0&\\cdots& \\sigma_m\\\\\n",
        "\\hline\n",
        "0&0&0&\\cdots&0\\\\\n",
        "\\vdots \n",
        "\\end{matrix}  \\right] \\\\ \\notag \\\\\n",
        "n < m :&&\n",
        "\\Sigma = \\left[\\begin{array}{c c c c c| c c}\n",
        "\\sigma_1 & 0& 0&\\cdots &0&0&\\cdots\\\\\n",
        "0& \\sigma_2 &0&\\cdots &0&0&\\cdots\\\\\n",
        "0&0& \\sigma_3 &\\cdots &0&0&\\cdots\\\\\n",
        "0&0&0&\\ddots&0&0&\\cdots\\\\\n",
        "0&0&0&\\cdots& \\sigma_n&0&\\cdots\n",
        "\\end{array}  \\right]\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt9sypzTcyKj"
      },
      "source": [
        "The singular values $\\sigma_i$ have a really important property and that is that they are all non-negative and are in decending order, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlX1i-AUdPlG"
      },
      "source": [
        "\\begin{align*}\n",
        "\\sigma_1 \\geq \\sigma_2 \\geq \\sigma_3 \\geq \\cdots \\geq\\sigma_{min\\{n, m\\}} \\geq 0\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpDi9hDDgLzP"
      },
      "source": [
        "To better understand the importance of this property, lets consider the case where $n>m$. The SVD looks like,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nISPOLgagbn7"
      },
      "source": [
        "\\begin{align*}\n",
        " X = \\left[ \n",
        "    \\begin{matrix}\n",
        "    | & | &  & | \\\\\n",
        "    u_1 & u_2  & \\cdots & u_n \\\\\n",
        "    | & | &  & |  \n",
        "    \\end{matrix}\n",
        "    \\right]\\left[\\begin{matrix}\n",
        "\\sigma_1 & 0& \\cdots &0\\\\\n",
        "0& \\sigma_2 &\\cdots &0\\\\\n",
        "0&0 &\\cdots &0\\\\\n",
        "0&0&\\ddots&0\\\\\n",
        "0&0&\\cdots& \\sigma_m\\\\\n",
        "\\hline\n",
        "0&0&\\cdots&0\\\\\n",
        "\\vdots \n",
        "\\end{matrix}  \\right] \\left[\\begin{matrix}\n",
        "    | & | &  & | \\\\\n",
        "    v_1 & v_2  & \\cdots & v_m \\\\\n",
        "    | & | &  & |  \n",
        "    \\end{matrix}\n",
        "    \\right]^* = \\sigma_1 u_1 v_1^* + \\sigma_2 u_2 v_2^* + \\cdots + \\sigma_m u_m v_m^* + 0\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtWRwemijnBq"
      },
      "source": [
        "We see that as terms are added in the SVD matrix expansion, the result approaches the original data matrix assymptotically (thanks to the decending magnitude of the $\\sigma$ values). This indicates the possibility of truncating the sum while still remaining close to representing the original data. Note that each product in the sum gives an $n\\times m$ matrix. We will take advantage of this property to perform image compression in the next section. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Qqa6-daVtS"
      },
      "source": [
        "For some additional intuition, lets consider the following product $Y = \\Sigma V^{*}$. The product above becomes $X = UY$. If the columns of $U$ are understood to form the unit basis of the space where all the columns of X exists, then each column of Y describe the exact mixture of these basis vectors needed to construct each corresponding column of X."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4pgucDdXdti"
      },
      "source": [
        "In summary,\n",
        "\n",
        "\\begin{align*}\n",
        "X = U \\Sigma V^*,\n",
        "\\end{align*}\n",
        "where, \n",
        "* $U$ is an $n\\times n$ square unitary matrix\n",
        "* $\\Sigma$ is an $n\\times m$ diagonal matrix with diagonal elements $\\sigma_i$ such that $\\sigma_1 \\geq \\sigma_2  \\geq \\cdots \\geq \\sigma_{min\\{n, m\\}} \\geq 0$\n",
        "* $V$ is an $m\\times m$ square unitary matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwR2vYv_UBaR"
      },
      "source": [
        "After learning of the properties that $U$, $V$, and $\\Sigma$ must have, one might question whether such matrices that satisfy the decomposition equation actually exists for every given data set. It turns out that not only do these matrices exist for all complex matrices $X$ (ie $X \\in \\mathbb{C}_{n\\times m}$), the decomposition is unique as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKYXUoZgVlSr"
      },
      "source": [
        "> **For any complex valued matrix $X$, there exist a unique set of matrices $U$, $V$, and $\\Sigma$ such that $U$, and $V$ are unitary and $\\Sigma$ is diagonal and $X = U\\Sigma V^*$.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO9d4_WWfnKl"
      },
      "source": [
        "## The Economy SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HiV-1hafspW"
      },
      "source": [
        "The nature of the sigma matrix is that it is an $n \\times m$ matrix with a non-zero diagonal. However, being that it is not a square matrix, there is a section of the matrix that must contain all zeros. If $n$ is the smaller of the two dimensions, then every component with an index that exceeds $n$ is zero. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF4BeedamKzC"
      },
      "source": [
        "\\begin{align*}\n",
        "\\Sigma = \\left[\\begin{array}{c c c c c| c c}\n",
        "\\sigma_1 & 0& 0&\\cdots &0&0&\\cdots\\\\\n",
        "0& \\sigma_2 &0&\\cdots &0&0&\\cdots\\\\\n",
        "0&0& \\sigma_3 &\\cdots &0&0&\\cdots\\\\\n",
        "0&0&0&\\ddots&0&0&\\cdots\\\\\n",
        "0&0&0&\\cdots& \\sigma_n&0&\\cdots\n",
        "\\end{array}  \\right]\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVakFJHAloAp"
      },
      "source": [
        "There is a computational consequence to this fact. The consequence is that some columns or rows of $U$ or $V$ will only every be multiplied by zero and will never end up contributing to the construction (or decomposition) of the original matrix $X$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8dsZBRBoehw"
      },
      "source": [
        "As a result, one immediate way to reduce the complexity and computational resources used in SVD calculations is to omit the rows or columns that do not contribute to the result of the calculation from the U and V matricies. Its low hanging fruit (so to say) because its something that can be done before the product is even computed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfyqgAmmohuz"
      },
      "source": [
        "The resulting SVD where these columns or rows are removed from either $U$ or $V$ (depending on which dimension is smaller) is called the Economy SVD."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SVD Part 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
